{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "eee530ef",
   "metadata": {},
   "source": [
    "Adam Peetz, Regis Jesuit University 2023 \n",
    "\n",
    " \n",
    " \n",
    "\n",
    "# Resizing Images \n",
    "\n",
    " \n",
    " \n",
    "\n",
    "Images scraped from the internet come in many different shapes and sizes. Convolutional neural networks (CNNs) need images to be scaled to a specific size before they can be input into the machine learning model. Scaling down images also reduces the amount of storage space they consume. This allows the model to use fewer resources during its training phase. <br> \n",
    "\n",
    " \n",
    " \n",
    "\n",
    "AlexNet, a seminal CNN research effort by Krizhevsky et al. (2017), employed an image processing pipeline that downscaled images to 256x256 prior to inputting them in the model. Rectangular images were rescaled around the shortest side, and then the center was cropped out of them. The authors also state that images should have the RGB values of the images centered, which reduces bias large pixel values may introduce to the weights of the model. The centering step is not included in the preprocessing code and is instead performed by the Keras API prior to loading the images into the model. Centering the pixel values during this stage of preprocessing will result in a series of black squares. These black squares can be used to successfully train the model but do not create an image set that makes sense to humans. <br> \n",
    "\n",
    " \n",
    " \n",
    "\n",
    "The first step of the pipeline defines the directory locations for source images and where to save them. The code then iterates through images in the directory. It assesses an image's length and width and then scales that image around 256 pixels by its shorter side. The center of these images is sliced from the image's array and saved to the output directory. <br> \n",
    "\n",
    " \n",
    " \n",
    "\n",
    "This code relies on the cv2 library supported by the OpenCV team (2023). \n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e89a7bce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 668/668 [00:20<00:00, 33.26it/s]\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import os\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "\n",
    "# create count variable\n",
    "i = 0\n",
    "\n",
    "# define file path for processing\n",
    "image_path = \"C:\\\\Users\\\\adamg\\\\Documents\\\\MSDS_692\\\\Week_2\\\\scraping_reddit\\\\datasets\\\\1\\\\\"\n",
    "save_path = \"C:\\\\Users\\\\adamg\\\\Documents\\\\MSDS_692\\\\Week_2\\\\scraping_reddit\\\\datasets\\\\1_out\\\\\"\n",
    "\n",
    "# iterate through files in directory and rename to sequential numbers\n",
    "for file in tqdm(os.listdir(image_path)):\n",
    "    \n",
    "    # read image to process\n",
    "    in_process_image = cv2.imread(os.path.join(image_path,file))  \n",
    "    \n",
    "    # get image width\n",
    "    image_width = in_process_image.shape[1]\n",
    "\n",
    "    # get image height\n",
    "    image_height = in_process_image.shape[0]\n",
    "    \n",
    "    # if image width is greater than or equal to height\n",
    "    if image_width >= image_height:\n",
    "        # calculate ratio to scale unfixed side\n",
    "        x_scale_ratio = int(image_width*(256/image_height))\n",
    "        # resize image \n",
    "        width_defined_image = cv2.resize(in_process_image, (x_scale_ratio,256))\n",
    "        # get dimensions for center crop\n",
    "        width_dim_left = int((x_scale_ratio/2)-128)\n",
    "        width_dim_right = int((x_scale_ratio/2)+128)\n",
    "        # apply center crop\n",
    "        cropped_width_defined_image = width_defined_image[:,width_dim_left:width_dim_right]\n",
    "        # write to file\n",
    "        name = str(i) + \".jpg\"\n",
    "        target = save_path + name\n",
    "        cv2.imwrite(target,cropped_width_defined_image)\n",
    "        i+=1\n",
    "        \n",
    "    # if image height is greater than width\n",
    "    if image_width < image_height:\n",
    "        # calculate ratio to scale unfixed side\n",
    "        y_scale_ratio = int(image_height*(256/image_width))\n",
    "        # resize image \n",
    "        height_defined_image = cv2.resize(in_process_image, (256,y_scale_ratio))\n",
    "        # get dimensions for center crop\n",
    "        height_dim_left = int((y_scale_ratio/2)-128)\n",
    "        height_dim_right = int((y_scale_ratio/2)+128)\n",
    "        # apply center crop\n",
    "        cropped_height_defined_image = height_defined_image[height_dim_left:height_dim_right,]\n",
    "        # write to file\n",
    "        name = str(i) + \".jpg\"\n",
    "        target = save_path + name\n",
    "        cv2.imwrite(target,cropped_height_defined_image)\n",
    "        i+=1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d66ee30b",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "Krizhevsky, Alex. Sutskever, Ilya. & Hinton, Geoffrey. (2017). ImageNet classification with deep convolutional neural netowkrs. Communications of the ACM. 60(8). DOI: 10.1145/3065386 <br>\n",
    "\n",
    "OpenCV Team. (2023). ComputerVision2 (cv2). Opencv.org"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
